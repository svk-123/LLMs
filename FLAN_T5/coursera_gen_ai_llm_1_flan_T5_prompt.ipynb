{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e2e917-1d0a-4541-aa11-eceea8e14e8d",
   "metadata": {},
   "source": [
    "#### Summarize Dialogue FLAN T5 model\n",
    "##### Ref:https://www.coursera.org/learn/generative-ai-with-llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7645967c-f0f8-4a8e-897e-d3c3ea06cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53548553-d63e-4336-b05f-7d073ab0aa1d",
   "metadata": {},
   "source": [
    "#### https://huggingface.co/datasets/knkarthick/dialogsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05f6eac0-7224-4424-a490-db66dffacb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"knkarthick/dialogsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "533225b1-9e0d-4cfb-bfd4-47d610aa21e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation', 'test'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d3c2a91-ed13-45d3-9ad4-2b1c959ecbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialogue:\n",
      "#Person1#: Happy Birthday, this is for you, Brian.\n",
      "#Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time.\n",
      "#Person1#: Brian, may I have a pleasure to have a dance with you?\n",
      "#Person2#: Ok.\n",
      "#Person1#: This is really wonderful party.\n",
      "#Person2#: Yes, you are always popular with everyone. and you look very pretty today.\n",
      "#Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel.\n",
      "#Person2#: You look great, you are absolutely glowing.\n",
      "#Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday\n",
      "\n",
      "summary:\n",
      "#Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n",
      "\n",
      "dialogue:\n",
      "#Person1#: What's wrong with you? Why are you scratching so much?\n",
      "#Person2#: I feel itchy! I can't stand it anymore! I think I may be coming down with something. I feel lightheaded and weak.\n",
      "#Person1#: Let me have a look. Whoa! Get away from me!\n",
      "#Person2#: What's wrong?\n",
      "#Person1#: I think you have chicken pox! You are contagious! Get away! Don't breathe on me!\n",
      "#Person2#: Maybe it's just a rash or an allergy! We can't be sure until I see a doctor.\n",
      "#Person1#: Well in the meantime you are a biohazard! I didn't get it when I was a kid and I've heard that you can even die if you get it as an adult!\n",
      "#Person2#: Are you serious? You always blow things out of proportion. In any case, I think I'll go take an oatmeal bath.\n",
      "\n",
      "summary:\n",
      "#Person1# thinks #Person2# has chicken pox and warns #Person2# about the possible hazards but #Person2# thinks it will be fine.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices = [10,20]\n",
    "for i, index in enumerate(example_indices):\n",
    "    print('dialogue:')\n",
    "    print(dataset['test'][index]['dialogue'])\n",
    "    print()\n",
    "    print('summary:')\n",
    "    print(dataset['test'][index]['summary'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9ee0318-b89e-48a9-a3a1-0f23e244f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='google/flan-t5-base'\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "940de622-0cfc-4d13-9151-750f3aa31ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6e18467-97be-4bdb-8820-81183d587b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  283,     7,     5, 31676,     6,    27,   174,    25,    12,   240,\n",
       "             3,     9,     3, 12194,   257,    21,   140,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Ms. Dawson, I need you to take a dictation for me\"\n",
    "prompt_encoded = tokenizer(sentence, return_tensors='pt')\n",
    "prompt_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f1800db-8f93-458e-87e9-7839a324dd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ms. Dawson, I need you to take a dictation for me'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_decoded = tokenizer.decode(\n",
    "        sentence_encoded[\"input_ids\"][0], \n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "prompt_decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53061b45-4a65-4925-9a5c-0ba329503a87",
   "metadata": {},
   "source": [
    "#### Summarize Dialogue without Prompt Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fbb4043-7911-48f9-b1eb-9ada4590cd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT PROMPT:\n",
      "\n",
      "#Person1#: Happy Birthday, this is for you, Brian.\n",
      "#Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time.\n",
      "#Person1#: Brian, may I have a pleasure to have a dance with you?\n",
      "#Person2#: Ok.\n",
      "#Person1#: This is really wonderful party.\n",
      "#Person2#: Yes, you are always popular with everyone. and you look very pretty today.\n",
      "#Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel.\n",
      "#Person2#: You look great, you are absolutely glowing.\n",
      "#Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday\n",
      "\n",
      "BASELINE HUMAN SUMMARY:\n",
      "\n",
      "#Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n",
      "\n",
      "MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\n",
      "\n",
      "Brian, thank you for coming to our party.\n",
      "\n",
      "INPUT PROMPT:\n",
      "\n",
      "#Person1#: What's wrong with you? Why are you scratching so much?\n",
      "#Person2#: I feel itchy! I can't stand it anymore! I think I may be coming down with something. I feel lightheaded and weak.\n",
      "#Person1#: Let me have a look. Whoa! Get away from me!\n",
      "#Person2#: What's wrong?\n",
      "#Person1#: I think you have chicken pox! You are contagious! Get away! Don't breathe on me!\n",
      "#Person2#: Maybe it's just a rash or an allergy! We can't be sure until I see a doctor.\n",
      "#Person1#: Well in the meantime you are a biohazard! I didn't get it when I was a kid and I've heard that you can even die if you get it as an adult!\n",
      "#Person2#: Are you serious? You always blow things out of proportion. In any case, I think I'll go take an oatmeal bath.\n",
      "\n",
      "BASELINE HUMAN SUMMARY:\n",
      "\n",
      "#Person1# thinks #Person2# has chicken pox and warns #Person2# about the possible hazards but #Person2# thinks it will be fine.\n",
      "\n",
      "MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\n",
      "\n",
      "Person1#: I'm scratching so much. I can't stand it anymore. I think I may be coming down with something. I feel lightheaded and weak.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, index in enumerate(example_indices):\n",
    "    # Extract dialogue and summary for the current example\n",
    "    dialogue = dataset['test'][index]['dialogue']\n",
    "    summary = dataset['test'][index]['summary']\n",
    "    \n",
    "    # Tokenize the dialogue input\n",
    "    inputs = tokenizer(dialogue, return_tensors='pt')\n",
    "    \n",
    "    # Generate a model output with a maximum of 50 new tokens\n",
    "    generated_output = model.generate(\n",
    "        inputs[\"input_ids\"], \n",
    "        max_new_tokens=50\n",
    "    )\n",
    "    \n",
    "    # Decode the generated output and skip special tokens\n",
    "    output = tokenizer.decode(\n",
    "        generated_output[0], \n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    # Print the input prompt (dialogue), baseline summary, and model output\n",
    "    print(f'INPUT PROMPT:\\n\\n{dialogue}\\n')\n",
    "    print(f'BASELINE HUMAN SUMMARY:\\n\\n{summary}\\n')\n",
    "    print(f'MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\\n\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea5083e-ed59-42f8-8c88-0ee646ce29f5",
   "metadata": {},
   "source": [
    "#### Zero Shot Inference with an Instruction Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62b22176-938c-471f-959a-36a18831f8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT PROMPT:\n",
      "\n",
      "#Person1#: Happy Birthday, this is for you, Brian.\n",
      "#Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time.\n",
      "#Person1#: Brian, may I have a pleasure to have a dance with you?\n",
      "#Person2#: Ok.\n",
      "#Person1#: This is really wonderful party.\n",
      "#Person2#: Yes, you are always popular with everyone. and you look very pretty today.\n",
      "#Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel.\n",
      "#Person2#: You look great, you are absolutely glowing.\n",
      "#Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday\n",
      "\n",
      "BASELINE HUMAN SUMMARY:\n",
      "\n",
      "#Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n",
      "\n",
      "MODEL GENERATION - ZERO SHOT INFERENCE:\n",
      "\n",
      "#Person1#: Happy birthday, Brian. #Person2#: I'm so happy you're having a good time. #Person1#: Thank you, I'm sure you look great today. #\n",
      "\n",
      "INPUT PROMPT:\n",
      "\n",
      "#Person1#: What's wrong with you? Why are you scratching so much?\n",
      "#Person2#: I feel itchy! I can't stand it anymore! I think I may be coming down with something. I feel lightheaded and weak.\n",
      "#Person1#: Let me have a look. Whoa! Get away from me!\n",
      "#Person2#: What's wrong?\n",
      "#Person1#: I think you have chicken pox! You are contagious! Get away! Don't breathe on me!\n",
      "#Person2#: Maybe it's just a rash or an allergy! We can't be sure until I see a doctor.\n",
      "#Person1#: Well in the meantime you are a biohazard! I didn't get it when I was a kid and I've heard that you can even die if you get it as an adult!\n",
      "#Person2#: Are you serious? You always blow things out of proportion. In any case, I think I'll go take an oatmeal bath.\n",
      "\n",
      "BASELINE HUMAN SUMMARY:\n",
      "\n",
      "#Person1# thinks #Person2# has chicken pox and warns #Person2# about the possible hazards but #Person2# thinks it will be fine.\n",
      "\n",
      "MODEL GENERATION - ZERO SHOT INFERENCE:\n",
      "\n",
      "#Person1#: I'm scratching so much. I can't stand it anymore. #Person2#: I think I have chicken pox. I'm contagious. #Person1#: I\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, index in enumerate(example_indices):\n",
    "    # Extract dialogue and summary for the current example\n",
    "    dialogue = dataset['test'][index]['dialogue']\n",
    "    summary = dataset['test'][index]['summary']\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Summarize the following conversation.\n",
    "    \n",
    "    {dialogue}\n",
    "    \n",
    "    Summary:\n",
    "        \"\"\"    \n",
    "    \n",
    "    # Tokenize the prompt input\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    \n",
    "    # Generate a model output with a maximum of 50 new tokens\n",
    "    generated_output = model.generate(\n",
    "        inputs[\"input_ids\"], \n",
    "        max_new_tokens=50\n",
    "    )\n",
    "    \n",
    "    # Decode the generated output and skip special tokens\n",
    "    output = tokenizer.decode(\n",
    "        generated_output[0], \n",
    "        skip_special_tokens=True\n",
    "    )    \n",
    "    # Print the input prompt (dialogue), baseline summary, and model output\n",
    "    print(f'INPUT PROMPT:\\n\\n{dialogue}\\n')\n",
    "    print(f'BASELINE HUMAN SUMMARY:\\n\\n{summary}\\n')\n",
    "    print(f'MODEL GENERATION - ZERO SHOT INFERENCE:\\n\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6a5a45-8573-418f-a31a-8067c5a8b89f",
   "metadata": {},
   "source": [
    "#### One Shot Inference with an Instruction Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1eadd704-003d-41fd-b88f-0fbb77a8fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(example_indices_full, example_index_to_summarize):\n",
    "    prompt = ''\n",
    "    for index in example_indices_full:\n",
    "        dialogue = dataset['test'][index]['dialogue']\n",
    "        summary = dataset['test'][index]['summary']\n",
    "        \n",
    "        # The stop sequence '{summary}\\n\\n\\n' is important for FLAN-T5. Other models may have their own preferred stop sequence.\n",
    "        prompt += f\"\"\"\n",
    "Dialogue:\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "What was going on?\n",
    "{summary}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    dialogue = dataset['test'][example_index_to_summarize]['dialogue']\n",
    "    \n",
    "    prompt += f\"\"\"\n",
    "Dialogue:\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "What was going on?\n",
    "\"\"\"\n",
    "        \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e62d10a-b992-492e-8b12-096196675e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dialogue:\n",
      "\n",
      "#Person1#: Yeah. Just pull on this strip. Then peel off the back.\n",
      "#Person2#: You might make a few enemies this way.\n",
      "#Person1#: If they don't think this is fun, they're not meant to be our friends.\n",
      "#Person2#: You mean your friends. I think it's cruel.\n",
      "#Person1#: Yeah. But it's fun. Look at those two ugly old ladies. . . or are they men?\n",
      "#Person2#: Hurry! Get a shot!. . . Hand it over!\n",
      "#Person1#: I knew you'd come around. . .\n",
      "\n",
      "What was going on?\n",
      "#Person1# is about to make a prank. #Person2# thinks it's cruel at first but then joins.\n",
      "\n",
      "\n",
      "\n",
      "Dialogue:\n",
      "\n",
      "#Person1#: Happy Birthday, this is for you, Brian.\n",
      "#Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time.\n",
      "#Person1#: Brian, may I have a pleasure to have a dance with you?\n",
      "#Person2#: Ok.\n",
      "#Person1#: This is really wonderful party.\n",
      "#Person2#: Yes, you are always popular with everyone. and you look very pretty today.\n",
      "#Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel.\n",
      "#Person2#: You look great, you are absolutely glowing.\n",
      "#Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday\n",
      "\n",
      "What was going on?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices_full = [50]\n",
    "example_index_to_summarize = 10\n",
    "one_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
    "print(one_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "63d6fc4f-fb6f-4f14-87b5-4cf28c0e2048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "#Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ONE SHOT:\n",
      "Brian's birthday is coming up.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the human-generated summary for the selected example\n",
    "summary = dataset['test'][example_index_to_summarize]['summary']\n",
    "\n",
    "# Tokenize the one-shot prompt\n",
    "inputs = tokenizer(one_shot_prompt, return_tensors='pt')\n",
    "\n",
    "# Generate model output with a max of 50 tokens\n",
    "generated_output = model.generate(\n",
    "    inputs[\"input_ids\"], \n",
    "    max_new_tokens=50\n",
    ")\n",
    "\n",
    "# Decode the model's output and skip special tokens\n",
    "output = tokenizer.decode(\n",
    "    generated_output[0], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ONE SHOT:\\n{output}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0336104d-6b75-495b-ae6e-2bb87d3c3aa9",
   "metadata": {},
   "source": [
    "#### Few Shot Inference with an Instruction Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e5dcbdf7-3fe6-4c91-83cf-6e5ecd1be9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dialogue:\n",
      "\n",
      "#Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "\n",
      "What was going on?\n",
      "#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "\n",
      "\n",
      "\n",
      "Dialogue:\n",
      "\n",
      "#Person1#: May, do you mind helping me prepare for the picnic?\n",
      "#Person2#: Sure. Have you checked the weather report?\n",
      "#Person1#: Yes. It says it will be sunny all day. No sign of rain at all. This is your father's favorite sausage. Sandwiches for you and Daniel.\n",
      "#Person2#: No, thanks Mom. I'd like some toast and chicken wings.\n",
      "#Person1#: Okay. Please take some fruit salad and crackers for me.\n",
      "#Person2#: Done. Oh, don't forget to take napkins disposable plates, cups and picnic blanket.\n",
      "#Person1#: All set. May, can you help me take all these things to the living room?\n",
      "#Person2#: Yes, madam.\n",
      "#Person1#: Ask Daniel to give you a hand?\n",
      "#Person2#: No, mom, I can manage it by myself. His help just causes more trouble.\n",
      "\n",
      "What was going on?\n",
      "Mom asks May to help to prepare for the picnic and May agrees.\n",
      "\n",
      "\n",
      "\n",
      "Dialogue:\n",
      "\n",
      "#Person1#: Happy Birthday, this is for you, Brian.\n",
      "#Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time.\n",
      "#Person1#: Brian, may I have a pleasure to have a dance with you?\n",
      "#Person2#: Ok.\n",
      "#Person1#: This is really wonderful party.\n",
      "#Person2#: Yes, you are always popular with everyone. and you look very pretty today.\n",
      "#Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel.\n",
      "#Person2#: You look great, you are absolutely glowing.\n",
      "#Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday\n",
      "\n",
      "What was going on?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices_full = [40, 80]\n",
    "example_index_to_summarize = 10\n",
    "\n",
    "few_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
    "\n",
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4ec96746-585f-4fae-ba11-3f9a4ac2734b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "#Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ONE SHOT:\n",
      "Brian's birthday is coming up. Brian's friends are coming over to celebrate.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the human-generated summary for the selected example\n",
    "summary = dataset['test'][example_index_to_summarize]['summary']\n",
    "\n",
    "# Tokenize the one-shot prompt\n",
    "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
    "\n",
    "# Generate model output with a max of 50 tokens\n",
    "generated_output = model.generate(\n",
    "    inputs[\"input_ids\"], \n",
    "    max_new_tokens=50\n",
    ")\n",
    "\n",
    "# Decode the model's output and skip special tokens\n",
    "output = tokenizer.decode(\n",
    "    generated_output[0], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ONE SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9b47a6-f728-4faa-a0bf-86d8b3930f80",
   "metadata": {},
   "source": [
    "##### Conclusion\n",
    "Prompt engineering does slightly better job than no prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
