{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da24a00-975b-4f2f-8d69-c2c348d3edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ref: Langchain in your pocket, Mehul Gupta\n",
    "#pip install chromadb==0.4.18 langchain==0.0.349 openai==1.3.8 tiktoken==0.5.2 jq youtube-transcript-api pytube unstructured pypdfium2\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/vino/api_keys')\n",
    "from api_key import OPENAI_API_KEY, OWM_API_KEY\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42b36543-65ed-4ef7-baf6-6efd2bffd704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import JSONLoader, YoutubeLoader, PyPDFium2Loader,TextLoader \n",
    "from langchain.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e37d4658-23d9-47e6-8041-ddeb75ed82e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading a text file using TextLoader.\n",
    "### reprocessing\n",
    "### Embeddings using OpenAIEmbeddings. We can use other models, such as BERT as well\n",
    "### Embeddings are stored in Chroma, which is a vector db.\n",
    "### Using the RetrieverQA chain, build a Retriever.\n",
    "### 4 type of documnet chain: stuff, Map Reduce, Refine, Map re rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3a29b5-822a-4a05-870f-19c2ba9d62fc",
   "metadata": {},
   "source": [
    "#### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34550d4a-9db2-4f40-a134-55c95f54e512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Document Loader\n",
    "loader = TextLoader(\"./data/dummy_data.txt\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d831b2-9243-4c9e-9780-9f57a9091dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Document Transformer\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57855e8c-d349-4063-812d-bf9afed290e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text embedding generation\n",
    "embeddings = OpenAIEmbeddings()\n",
    "llm=OpenAI(model_name=\"gpt-3.5-turbo-instruct\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "486d141e-e46e-49cb-b55f-774eaa6e5aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector DB\n",
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc66c3fc-b1ec-4d05-b426-168dc480df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retriever\n",
    "qa=RetrievalQA.from_chain_type(llm=llm,chain_type=\"stuff\",retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2ef837-d214-4e2b-a027-76bae75a02c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I'm sorry, I cannot see an attached file. Could you please provide more information or clarify your question?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run('explain the attached file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdd04d68-67c8-49f6-917d-5b4196a0982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### query other file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57fe0ad9-fea0-4e7d-b91d-fe17df066844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #CSV\n",
    "# loader = CSVLoader(file_path='./data/dummy_data.csv')\n",
    "# data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "308655b3-e7f2-426b-ab33-1f9d65265b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #PDF\n",
    "# loader = PyPDFium2Loader(\"./data/dummy_data.pdf\")\n",
    "# data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "676d225f-4481-4106-ac36-d19e53225499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #YouTube\n",
    "# loader = YoutubeLoader.from_youtube_url(\n",
    "# \"https://www.youtube.com/watch?v=D0S2YOVyFUE\",\n",
    "#     add_video_info=True,\n",
    "#     language=[\"en\", \"id\"],\n",
    "#     translation=\"en\",\n",
    "# )\n",
    "# data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae3d1dd9-d260-4fa3-ada3-2f15c4790e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #JSON\n",
    "# loader = JSONLoader(\n",
    "#     file_path='dummy_data.json',\n",
    "#     text_content=False,\n",
    "#     jq_schema='.[].name')\n",
    "\n",
    "# data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45febf94-3988-4304-b8bf-d0b7837e976c",
   "metadata": {},
   "source": [
    "#### Multi-Document RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9ed0e3c-9aa4-4c82-a623-0a1a7d7a4e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import AgentExecutor, initialize_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools import BaseTool, StructuredTool, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15948eaf-8cb5-4b8c-adb0-116c7d3fd4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text embedding generation\n",
    "embeddings = OpenAIEmbeddings()\n",
    "llm=OpenAI(model_name=\"gpt-3.5-turbo-instruct\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7348121c-a121-48fd-a41b-5f3a5a3972bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever_qa_creation(file_name):\n",
    "    loader = TextLoader(file_name)\n",
    "    documents = loader.load()\n",
    "    text_splitter=CharacterTextSplitter(chunk_size=100,chunk_overlap=0)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    db = Chroma.from_documents(texts, embeddings)\n",
    "    qa=RetrievalQA.from_chain_type(llm=llm,chain_type=\"stuff\", retriever=db.as_retriever())\n",
    "\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90ca4046-7464-41c3-8ba7-34c0b56ce8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 259, which is longer than the specified 100\n",
      "Created a chunk of size 4976, which is longer than the specified 100\n",
      "Created a chunk of size 701, which is longer than the specified 100\n",
      "Created a chunk of size 534, which is longer than the specified 100\n"
     ]
    }
   ],
   "source": [
    "retriever_qa1 = retriever_qa_creation('./data/dummy_data.txt')\n",
    "retriever_qa2 = retriever_qa_creation('./data/dummy_data2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "930fd770-9411-4c5c-bca4-a7b657055671",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def medium_tips(query: str)->str:\n",
    "    \"\"\"search to extract tips and tricks to write blogs on Medium\"\"\"\n",
    "    return retriever_qa1.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "294819d5-91ed-44aa-93bc-66862caec924",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def blog_tips(query: str)->str: \n",
    "    \"\"\"explains the pros and cons of writing blogs as a data scientist\"\"\"\n",
    "    return retriever_qa2.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4581664-bcfa-45ad-9ae0-1c610f211937",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools =[medium_tips,blog_tips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d15f9777-652d-4c68-8e56-f84aaac4b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "agent_chain=initialize_agent(tools,llm,agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, verbose=True,memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fb1da9a-6f61-4eb3-bf7c-daa7b7c6899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: blog_tips\n",
      "Action Input: Why should Data Scientists blog?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Data scientists should blog to share their knowledge and insights with others in the field, to showcase their skills and expertise, and to contribute to the larger data science community. Blogging can also help data scientists improve their communication and writing skills, as well as stay updated on the latest trends and developments in the field. Additionally, blogging can help data scientists build their personal brand and establish themselves as thought leaders in the industry.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: Blogging can also be a great way for data scientists to network and connect with others in the field, as well as potential employers or clients. It can also be a valuable addition to a data scientist's portfolio and resume.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Blogging can also be a great way for data scientists to network and connect with others in the field, as well as potential employers or clients. It can also be a valuable addition to a data scientist's portfolio and resume.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run({'input':'Why should Data Scientists blog??'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2553e7b8-dabd-4269-bf62-4100eadd7ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: medium_tips\n",
      "Action Input: who is vinothkumar\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Vinothkumar is a person who has a Doctor of Philosophy in Computational Science and has experience in data-driven problem solving in both academic and industrial settings. They are proficient in managing large-scale production data and performing analytics, and have skills in statistics, machine learning, deep learning, and other technical areas. They have also published research articles and mentored others in the development of machine learning models for engineering applications.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: Vinothkumar is a highly skilled data scientist with a strong background in computational science and experience in various technical areas such as statistics and machine learning. They have also published research articles and mentored others in the development of machine learning models.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Vinothkumar is a highly skilled data scientist with a strong background in computational science and experience in various technical areas such as statistics and machine learning. They have also published research articles and mentored others in the development of machine learning models.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run({'input':'who is vinothkumar'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
